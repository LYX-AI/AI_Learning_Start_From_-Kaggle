{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Getting started with NLP for absolute beginners",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "26f91a16ef004bd1ad489ebb2a52f2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf41dea108b6442c96bdf244e4aa2280",
              "IPY_MODEL_d1193ff9ba78444699afca3724bc1062",
              "IPY_MODEL_1a57f0b9bdb440838045d7e903a6fdf1"
            ],
            "layout": "IPY_MODEL_e142c03a502946d188c30aa34c33ec34"
          }
        },
        "cf41dea108b6442c96bdf244e4aa2280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf0061a96e8347429b3f5a13fc95d945",
            "placeholder": "​",
            "style": "IPY_MODEL_9f815e599d534604ab619c27fb57c26c",
            "value": "Map: 100%"
          }
        },
        "d1193ff9ba78444699afca3724bc1062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_843524e8755946b9826509e224fec1ed",
            "max": 3000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e29eb77fc72441b847af01d6898b4c8",
            "value": 3000
          }
        },
        "1a57f0b9bdb440838045d7e903a6fdf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22968bee4ca348ecab4801eccaef37c6",
            "placeholder": "​",
            "style": "IPY_MODEL_c71bcf5e12314d519b974325aa0e99c5",
            "value": " 3000/3000 [00:00&lt;00:00, 4567.66 examples/s]"
          }
        },
        "e142c03a502946d188c30aa34c33ec34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf0061a96e8347429b3f5a13fc95d945": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f815e599d534604ab619c27fb57c26c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "843524e8755946b9826509e224fec1ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e29eb77fc72441b847af01d6898b4c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22968bee4ca348ecab4801eccaef37c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c71bcf5e12314d519b974325aa0e99c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LYX-AI/AI_Learning_Start_From_-Kaggle/blob/main/Getting_started_with_NLP_for_absolute_beginners.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "LiRRYrC45g_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One area where deep learning has dramatically improved in the last couple of years is natural language processing (NLP). Computers can now generate text, translate automatically from one language to another, analyze comments, label words in sentences, and much more.\n",
        "\n",
        "Perhaps the most widely practically useful application of NLP is *classification* -- that is, classifying a document automatically into some category. This can be used, for instance, for:\n",
        "\n",
        "- Sentiment analysis (e.g are people saying *positive* or *negative* things about your product)\n",
        "- Author identification (what author most likely wrote some document)\n",
        "- Legal discovery (which documents are in scope for a trial)\n",
        "- Organizing documents by topic\n",
        "- Triaging inbound emails\n",
        "- ...and much more!\n",
        "\n",
        "Classification models can also be used to solve problems that are not, at first, obviously appropriate. For instance, consider the Kaggle [U.S. Patent Phrase to Phrase Matching](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/) competition. In this, we are tasked with comparing two words or short phrases, and scoring them based on whether they're similar or not, based on which patent class they were used in. With a score of `1` it is considered that the two inputs have identical meaning, and `0` means they have totally different meaning. For instance, *abatement* and *eliminating process* have a score of `0.5`, meaning they're somewhat similar, but not identical.\n",
        "\n",
        "It turns out that this can be represented as a classification problem. How? By representing the question like this:\n",
        "\n",
        "> For the following text...: \"TEXT1: abatement; TEXT2: eliminating process\" ...chose a category of meaning similarity: \"Different; Similar; Identical\".\n",
        "\n",
        "In this notebook we'll see how to solve the Patent Phrase Matching problem by treating it as a classification task, by representing it in a very similar way to that shown above."
      ],
      "metadata": {
        "id": "yumD7ttj5g_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### On Kaggle"
      ],
      "metadata": {
        "id": "W85oqWUd5g_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kaggle is an awesome resource for aspiring data scientists or anyone looking to improve their machine learning skills. There is nothing like being able to get hands-on practice and receiving real-time feedback to help you improve your skills. It provides:\n",
        "\n",
        "1. Interesting data sets\n",
        "1. Feedback on how you're doing\n",
        "1. A leader board to see what's good, what's possible, and what's state-of-art\n",
        "1. Notebooks and blog posts by winning contestants share useful tips and techniques.\n",
        "\n",
        "The dataset we will be using here is only available from Kaggle. Therefore, you will need to register on the site, then go to the [page for the competition](https://www.kaggle.com/c/us-patent-phrase-to-phrase-matching). On that page click \"Rules,\" then \"I Understand and Accept.\" (Although the competition has finished, and you will not be entering it, you still have to agree to the rules to be allowed to download the data.)\n",
        "\n",
        "There are two ways to then use this data:\n",
        "\n",
        "- Easiest: run this notebook directly on Kaggle, or\n",
        "- Most flexible: download the data locally and run it on your PC or GPU server\n",
        "\n",
        "If you are running this on Kaggle.com, you can skip the next section. Just make sure that on Kaggle you've selected to use a GPU during your session, by clicking on the hamburger menu (3 dots in the top right) and clicking \"Accelerator\" -- it should look like this:"
      ],
      "metadata": {
        "id": "wsS7jI2T5g_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](attachment:9af4e875-1f2a-468c-b233-8c91531e4c40.png)!"
      ],
      "metadata": {
        "id": "eHnwPYzF5g_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll need slightly different code depending on whether we're running on Kaggle or not, so we'll use this variable to track where we are:"
      ],
      "metadata": {
        "id": "f9aurNVK5g_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:15.587736Z",
          "iopub.execute_input": "2022-04-19T22:50:15.588105Z",
          "iopub.status.idle": "2022-04-19T22:50:15.617766Z",
          "shell.execute_reply.started": "2022-04-19T22:50:15.58802Z",
          "shell.execute_reply": "2022-04-19T22:50:15.617115Z"
        },
        "trusted": true,
        "id": "P69yuEq05g_k"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Kaggle data on your own machine"
      ],
      "metadata": {
        "id": "MlQBNM_m5g_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kaggle limits your weekly time using a GPU machine. The limits are very generous, but you may well still find it's not enough! In that case, you'll want to use your own GPU server, or a cloud server such as Colab, Paperspace Gradient, or SageMaker Studio Lab (all of which have free options). To do so, you'll need to be able to download Kaggle datasets.\n",
        "\n",
        "The easiest way to download Kaggle datasets is to use the Kaggle API. You can install this using `pip` by running this in a notebook cell:\n",
        "\n",
        "    !pip install kaggle\n",
        "\n",
        "You need an API key to use the Kaggle API; to get one, click on your profile picture on the Kaggle website, and choose My Account, then click Create New API Token. This will save a file called *kaggle.json* to your PC. You need to copy this key on your GPU server. To do so, open the file you downloaded, copy the contents, and paste them in the following cell (e.g., `creds = '{\"username\":\"xxx\",\"key\":\"xxx\"}'`):"
      ],
      "metadata": {
        "id": "FdJi821G5g_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "creds = ''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:15.619247Z",
          "iopub.execute_input": "2022-04-19T22:50:15.619569Z",
          "iopub.status.idle": "2022-04-19T22:50:15.623522Z",
          "shell.execute_reply.started": "2022-04-19T22:50:15.619534Z",
          "shell.execute_reply": "2022-04-19T22:50:15.622704Z"
        },
        "trusted": true,
        "id": "JqU26vmd5g_l"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then execute this cell (this only needs to be run once):"
      ],
      "metadata": {
        "id": "cSol4R-B5g_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for working with paths in Python, I recommend using `pathlib.Path`\n",
        "from pathlib import Path\n",
        "\n",
        "cred_path = Path('~/.kaggle/kaggle.json').expanduser()\n",
        "if not cred_path.exists():\n",
        "    cred_path.parent.mkdir(exist_ok=True)\n",
        "    cred_path.write_text(creds)\n",
        "    cred_path.chmod(0o600)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:15.624716Z",
          "iopub.execute_input": "2022-04-19T22:50:15.625489Z",
          "iopub.status.idle": "2022-04-19T22:50:15.633519Z",
          "shell.execute_reply.started": "2022-04-19T22:50:15.625454Z",
          "shell.execute_reply": "2022-04-19T22:50:15.632834Z"
        },
        "trusted": true,
        "id": "piC0thOJ5g_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can download datasets from Kaggle."
      ],
      "metadata": {
        "id": "89Z98dp55g_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = Path('us-patent-phrase-to-phrase-matching')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:15.635423Z",
          "iopub.execute_input": "2022-04-19T22:50:15.636204Z",
          "iopub.status.idle": "2022-04-19T22:50:15.642688Z",
          "shell.execute_reply.started": "2022-04-19T22:50:15.636168Z",
          "shell.execute_reply": "2022-04-19T22:50:15.642098Z"
        },
        "trusted": true,
        "id": "5YMty0A75g_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And use the Kaggle API to download the dataset to that path, and extract it:"
      ],
      "metadata": {
        "id": "-44Bw7Sd5g_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not iskaggle and not path.exists():\n",
        "    import zipfile,kaggle\n",
        "    kaggle.api.competition_download_cli(str(path))\n",
        "    zipfile.ZipFile(f'{path}.zip').extractall(path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:15.645546Z",
          "iopub.execute_input": "2022-04-19T22:50:15.645766Z",
          "iopub.status.idle": "2022-04-19T22:50:15.651722Z",
          "shell.execute_reply.started": "2022-04-19T22:50:15.645742Z",
          "shell.execute_reply": "2022-04-19T22:50:15.650984Z"
        },
        "trusted": true,
        "id": "5HJAjYCn5g_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that you can easily download notebooks from Kaggle and upload them to other cloud services. So if you're low on Kaggle GPU credits, give this a try!"
      ],
      "metadata": {
        "id": "1hO9ACO75g_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import and EDA"
      ],
      "metadata": {
        "id": "9u_DxDTR5g_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# 判断是否在 Kaggle 环境\n",
        "iskaggle = 'kaggle' in sys.modules\n",
        "\n",
        "if iskaggle:\n",
        "    path = Path('../input/us-patent-phrase-to-phrase-matching')\n",
        "else:\n",
        "    # Colab 上的数据路径，假设你上传或下载到这里\n",
        "    path = Path('/content/sample_data')\n",
        "\n",
        "# 安装依赖库，Colab 和 Kaggle 都适用\n",
        "!pip install -q datasets\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:15.652746Z",
          "iopub.execute_input": "2022-04-19T22:50:15.653663Z",
          "iopub.status.idle": "2022-04-19T22:50:24.31782Z",
          "shell.execute_reply.started": "2022-04-19T22:50:15.653623Z",
          "shell.execute_reply": "2022-04-19T22:50:24.317005Z"
        },
        "trusted": true,
        "id": "TIiULedS5g_n"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Documents in NLP datasets are generally in one of two main forms:\n",
        "\n",
        "- **Larger documents**: One text file per document, often organised into one folder per category\n",
        "- **Smaller documents**: One document (or document pair, optionally with metadata) per row in a [CSV file](https://realpython.com/python-csv/).\n",
        "\n",
        "Let's look at our data and see what we've got. In Jupyter you can use any bash/shell command by starting a line with a `!`, and use `{}` to include python variables, like so:"
      ],
      "metadata": {
        "id": "tP6Bed9R5g_n"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XLjK6At1Ezj4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls {path}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:24.319918Z",
          "iopub.execute_input": "2022-04-19T22:50:24.320225Z",
          "iopub.status.idle": "2022-04-19T22:50:25.026182Z",
          "shell.execute_reply.started": "2022-04-19T22:50:24.320172Z",
          "shell.execute_reply": "2022-04-19T22:50:25.025396Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh3usaP05g_n",
        "outputId": "df050e6c-69af-4c1d-d968-498fbb367443"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anscombe.json\t\t      mnist_test.csv\n",
            "california_housing_test.csv   mnist_train_small.csv\n",
            "california_housing_train.csv  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like this competition uses CSV files. For opening, manipulating, and viewing CSV files, it's generally best to use the Pandas library, which is explained brilliantly in [this book](https://wesmckinney.com/book/) by the lead developer (it's also an excellent introduction to matplotlib and numpy, both of which I use in this notebook). Generally it's imported as the abbreviation `pd`."
      ],
      "metadata": {
        "id": "Gs7We8r15g_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:25.029087Z",
          "iopub.execute_input": "2022-04-19T22:50:25.029405Z",
          "iopub.status.idle": "2022-04-19T22:50:25.033899Z",
          "shell.execute_reply.started": "2022-04-19T22:50:25.029375Z",
          "shell.execute_reply": "2022-04-19T22:50:25.033097Z"
        },
        "trusted": true,
        "id": "ATnLCyt15g_n"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's set a path to our data:"
      ],
      "metadata": {
        "id": "Bx7rAsTt5g_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "pd 是 Pandas 库的别名，read_csv 是 Pandas 中用于读取 CSV 文件的函数。\n",
        "\n",
        "path 是一个 Path 对象，表示数据所在的目录路径。\n",
        "\n",
        "path / 'train.csv' 表示在 path 路径下的文件 train.csv，这是用 Python pathlib 库拼接路径的写法，相当于字符串拼接 path + '/train.csv'。\n",
        "\n",
        "pd.read_csv() 会读取指定路径的 CSV 文件内容，返回一个 Pandas 的 DataFrame 对象，存储该 CSV 文件中的表格数据。\n",
        "\n",
        "df 是变量名，表示存放读取后数据的表格，方便后续数据操作、分析和处理。\n",
        "'''\n",
        "df = pd.read_csv(path/'california_housing_test.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:25.035596Z",
          "iopub.execute_input": "2022-04-19T22:50:25.036233Z",
          "iopub.status.idle": "2022-04-19T22:50:25.118872Z",
          "shell.execute_reply.started": "2022-04-19T22:50:25.036197Z",
          "shell.execute_reply": "2022-04-19T22:50:25.118154Z"
        },
        "trusted": true,
        "id": "0Msirbjr5g_o"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This creates a [DataFrame](https://pandas.pydata.org/docs/user_guide/10min.html), which is a table of named columns, a bit like a database table. To view the first and last rows, and row count of a DataFrame, just type its name:"
      ],
      "metadata": {
        "id": "0c5G4V7j5g_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:25.122029Z",
          "iopub.execute_input": "2022-04-19T22:50:25.122228Z",
          "iopub.status.idle": "2022-04-19T22:50:25.148288Z",
          "shell.execute_reply.started": "2022-04-19T22:50:25.122204Z",
          "shell.execute_reply": "2022-04-19T22:50:25.147661Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "DuPlveA95g_o",
        "outputId": "9f26c10b-69b5-431c-87aa-8fc9c1c016ce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0       -122.05     37.37                27.0       3885.0           661.0   \n",
              "1       -118.30     34.26                43.0       1510.0           310.0   \n",
              "2       -117.81     33.78                27.0       3589.0           507.0   \n",
              "3       -118.36     33.82                28.0         67.0            15.0   \n",
              "4       -119.67     36.33                19.0       1241.0           244.0   \n",
              "...         ...       ...                 ...          ...             ...   \n",
              "2995    -119.86     34.42                23.0       1450.0           642.0   \n",
              "2996    -118.14     34.06                27.0       5257.0          1082.0   \n",
              "2997    -119.70     36.30                10.0        956.0           201.0   \n",
              "2998    -117.12     34.10                40.0         96.0            14.0   \n",
              "2999    -119.63     34.42                42.0       1765.0           263.0   \n",
              "\n",
              "      population  households  median_income  median_house_value  \n",
              "0         1537.0       606.0         6.6085            344700.0  \n",
              "1          809.0       277.0         3.5990            176500.0  \n",
              "2         1484.0       495.0         5.7934            270500.0  \n",
              "3           49.0        11.0         6.1359            330000.0  \n",
              "4          850.0       237.0         2.9375             81700.0  \n",
              "...          ...         ...            ...                 ...  \n",
              "2995      1258.0       607.0         1.1790            225000.0  \n",
              "2996      3496.0      1036.0         3.3906            237200.0  \n",
              "2997       693.0       220.0         2.2895             62000.0  \n",
              "2998        46.0        14.0         3.2708            162500.0  \n",
              "2999       753.0       260.0         8.5608            500001.0  \n",
              "\n",
              "[3000 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e5c1069-ea8f-4af4-aec0-9d5e970571ed\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-122.05</td>\n",
              "      <td>37.37</td>\n",
              "      <td>27.0</td>\n",
              "      <td>3885.0</td>\n",
              "      <td>661.0</td>\n",
              "      <td>1537.0</td>\n",
              "      <td>606.0</td>\n",
              "      <td>6.6085</td>\n",
              "      <td>344700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-118.30</td>\n",
              "      <td>34.26</td>\n",
              "      <td>43.0</td>\n",
              "      <td>1510.0</td>\n",
              "      <td>310.0</td>\n",
              "      <td>809.0</td>\n",
              "      <td>277.0</td>\n",
              "      <td>3.5990</td>\n",
              "      <td>176500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-117.81</td>\n",
              "      <td>33.78</td>\n",
              "      <td>27.0</td>\n",
              "      <td>3589.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>1484.0</td>\n",
              "      <td>495.0</td>\n",
              "      <td>5.7934</td>\n",
              "      <td>270500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-118.36</td>\n",
              "      <td>33.82</td>\n",
              "      <td>28.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.1359</td>\n",
              "      <td>330000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-119.67</td>\n",
              "      <td>36.33</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1241.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>850.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>2.9375</td>\n",
              "      <td>81700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>-119.86</td>\n",
              "      <td>34.42</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1450.0</td>\n",
              "      <td>642.0</td>\n",
              "      <td>1258.0</td>\n",
              "      <td>607.0</td>\n",
              "      <td>1.1790</td>\n",
              "      <td>225000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>-118.14</td>\n",
              "      <td>34.06</td>\n",
              "      <td>27.0</td>\n",
              "      <td>5257.0</td>\n",
              "      <td>1082.0</td>\n",
              "      <td>3496.0</td>\n",
              "      <td>1036.0</td>\n",
              "      <td>3.3906</td>\n",
              "      <td>237200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>-119.70</td>\n",
              "      <td>36.30</td>\n",
              "      <td>10.0</td>\n",
              "      <td>956.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>693.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>2.2895</td>\n",
              "      <td>62000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>-117.12</td>\n",
              "      <td>34.10</td>\n",
              "      <td>40.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>3.2708</td>\n",
              "      <td>162500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>-119.63</td>\n",
              "      <td>34.42</td>\n",
              "      <td>42.0</td>\n",
              "      <td>1765.0</td>\n",
              "      <td>263.0</td>\n",
              "      <td>753.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>8.5608</td>\n",
              "      <td>500001.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e5c1069-ea8f-4af4-aec0-9d5e970571ed')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8e5c1069-ea8f-4af4-aec0-9d5e970571ed button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8e5c1069-ea8f-4af4-aec0-9d5e970571ed');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-20501553-6384-407b-afca-126c23fd3870\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-20501553-6384-407b-afca-126c23fd3870')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-20501553-6384-407b-afca-126c23fd3870 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_1278942f-a7fc-4ac7-9891-1b653fe9f68e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1278942f-a7fc-4ac7-9891-1b653fe9f68e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9949362939550161,\n        \"min\": -124.18,\n        \"max\": -114.49,\n        \"num_unique_values\": 607,\n        \"samples\": [\n          -121.15,\n          -121.46,\n          -121.02\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1296695233438325,\n        \"min\": 32.56,\n        \"max\": 41.92,\n        \"num_unique_values\": 587,\n        \"samples\": [\n          40.17,\n          33.69,\n          39.61\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"housing_median_age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.555395554955755,\n        \"min\": 1.0,\n        \"max\": 52.0,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          14.0,\n          49.0,\n          7.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_rooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2155.59333162558,\n        \"min\": 6.0,\n        \"max\": 30450.0,\n        \"num_unique_values\": 2215,\n        \"samples\": [\n          1961.0,\n          1807.0,\n          680.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_bedrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 415.6543681363232,\n        \"min\": 2.0,\n        \"max\": 5419.0,\n        \"num_unique_values\": 1055,\n        \"samples\": [\n          532.0,\n          764.0,\n          2162.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"population\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1030.5430124122422,\n        \"min\": 5.0,\n        \"max\": 11935.0,\n        \"num_unique_values\": 1802,\n        \"samples\": [\n          947.0,\n          1140.0,\n          2019.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"households\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 365.42270980552604,\n        \"min\": 2.0,\n        \"max\": 4930.0,\n        \"num_unique_values\": 1026,\n        \"samples\": [\n          646.0,\n          629.0,\n          504.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.854511729691481,\n        \"min\": 0.4999,\n        \"max\": 15.0001,\n        \"num_unique_values\": 2578,\n        \"samples\": [\n          1.725,\n          0.7403,\n          2.6964\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_house_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 113119.68746964433,\n        \"min\": 22500.0,\n        \"max\": 500001.0,\n        \"num_unique_values\": 1784,\n        \"samples\": [\n          71900.0,\n          63000.0,\n          115800.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's important to carefully read the [dataset description](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/data) to understand how each of these columns is used.\n",
        "\n",
        "One of the most useful features of `DataFrame` is the `describe()` method:"
      ],
      "metadata": {
        "id": "xWgK0vCv5g_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "describe() 默认对数值型数据做统计汇总，比如计数（count）、均值（mean）、标准差（std）、最小值（min）、四分位数（25%、50%、75%）和最大值（max）。\n",
        "\n",
        "当你指定参数 include='object'，表示只对数据类型为“object”（通常指字符串或类别型数据）的列进行统计描述。\n",
        "\n",
        "统计结果一般包含\n",
        "count：非空值的数量\n",
        "\n",
        "unique：不同值的个数\n",
        "\n",
        "top：出现频率最高的值（众数）\n",
        "\n",
        "freq：最高频值出现的次数\n",
        "'''\n",
        "df['total_rooms'].describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:25.149508Z",
          "iopub.execute_input": "2022-04-19T22:50:25.149775Z",
          "iopub.status.idle": "2022-04-19T22:50:25.224974Z",
          "shell.execute_reply.started": "2022-04-19T22:50:25.149735Z",
          "shell.execute_reply": "2022-04-19T22:50:25.224207Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "8I0aW4CA5g_o",
        "outputId": "d94fc5eb-5f4c-42e4-da04-8001c3dd619c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     3000.000000\n",
              "mean      2599.578667\n",
              "std       2155.593332\n",
              "min          6.000000\n",
              "25%       1401.000000\n",
              "50%       2106.000000\n",
              "75%       3129.000000\n",
              "max      30450.000000\n",
              "Name: total_rooms, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_rooms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2599.578667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2155.593332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1401.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2106.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3129.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>30450.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that in the 36473 rows, there are 733 unique anchors, 106 contexts, and nearly 30000 targets. Some anchors are very common, with \"component composite coating\" for instance appearing 152 times.\n",
        "\n",
        "Earlier, I suggested we could represent the input to the model as something like \"*TEXT1: abatement; TEXT2: eliminating process*\". We'll need to add the context to this too. In Pandas, we just use `+` to concatenate, like so:"
      ],
      "metadata": {
        "id": "httTyABG5g_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['description'] = (\n",
        "    'Location: (' + df['longitude'].astype(str) + ', ' + df['latitude'].astype(str) + '); ' +\n",
        "    'Median house value: $' + df['median_house_value'].astype(str)\n",
        ")\n",
        "print(df[['longitude', 'latitude', 'median_house_value', 'description']])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:25.22633Z",
          "iopub.execute_input": "2022-04-19T22:50:25.226581Z",
          "iopub.status.idle": "2022-04-19T22:50:25.256756Z",
          "shell.execute_reply.started": "2022-04-19T22:50:25.226549Z",
          "shell.execute_reply": "2022-04-19T22:50:25.256142Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6gv32sR5g_o",
        "outputId": "31bc91ef-90fb-486c-91ea-be241d69ef62"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      longitude  latitude  median_house_value  \\\n",
            "0       -122.05     37.37            344700.0   \n",
            "1       -118.30     34.26            176500.0   \n",
            "2       -117.81     33.78            270500.0   \n",
            "3       -118.36     33.82            330000.0   \n",
            "4       -119.67     36.33             81700.0   \n",
            "...         ...       ...                 ...   \n",
            "2995    -119.86     34.42            225000.0   \n",
            "2996    -118.14     34.06            237200.0   \n",
            "2997    -119.70     36.30             62000.0   \n",
            "2998    -117.12     34.10            162500.0   \n",
            "2999    -119.63     34.42            500001.0   \n",
            "\n",
            "                                            description  \n",
            "0     Location: (-122.05, 37.37); Median house value...  \n",
            "1     Location: (-118.3, 34.26); Median house value:...  \n",
            "2     Location: (-117.81, 33.78); Median house value...  \n",
            "3     Location: (-118.36, 33.82); Median house value...  \n",
            "4     Location: (-119.67, 36.33); Median house value...  \n",
            "...                                                 ...  \n",
            "2995  Location: (-119.86, 34.42); Median house value...  \n",
            "2996  Location: (-118.14, 34.06); Median house value...  \n",
            "2997  Location: (-119.7, 36.3); Median house value: ...  \n",
            "2998  Location: (-117.12, 34.1); Median house value:...  \n",
            "2999  Location: (-119.63, 34.42); Median house value...  \n",
            "\n",
            "[3000 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can refer to a column (also known as a *series*) either using regular python \"dotted\" notation, or access it like a dictionary. To get the first few rows, use `head()`:"
      ],
      "metadata": {
        "id": "CK9zwzAy5g_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['total_rooms'].head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:25.258073Z",
          "iopub.execute_input": "2022-04-19T22:50:25.258323Z",
          "iopub.status.idle": "2022-04-19T22:50:25.266369Z",
          "shell.execute_reply.started": "2022-04-19T22:50:25.25829Z",
          "shell.execute_reply": "2022-04-19T22:50:25.26554Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "gIJzbRZl5g_p",
        "outputId": "9139c4fa-60f2-42de-9350-b92619950817"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    3885.0\n",
              "1    1510.0\n",
              "2    3589.0\n",
              "3      67.0\n",
              "4    1241.0\n",
              "Name: total_rooms, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_rooms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3885.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1510.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3589.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>67.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1241.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "mdDTGUo85g_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformers uses a `Dataset` object for storing a... well a dataset, of course! We can create one like so:"
      ],
      "metadata": {
        "id": "h11z4OiP5g_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset,DatasetDict\n",
        "\n",
        "ds = Dataset.from_pandas(df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:25.267623Z",
          "iopub.execute_input": "2022-04-19T22:50:25.267941Z",
          "iopub.status.idle": "2022-04-19T22:50:27.33017Z",
          "shell.execute_reply.started": "2022-04-19T22:50:25.267906Z",
          "shell.execute_reply": "2022-04-19T22:50:27.32933Z"
        },
        "trusted": true,
        "id": "N3O8Mz4i5g_p"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's how it's displayed in a notebook:"
      ],
      "metadata": {
        "id": "7E4la27V5g_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:27.331409Z",
          "iopub.execute_input": "2022-04-19T22:50:27.3318Z",
          "iopub.status.idle": "2022-04-19T22:50:27.343688Z",
          "shell.execute_reply.started": "2022-04-19T22:50:27.331754Z",
          "shell.execute_reply": "2022-04-19T22:50:27.34289Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOvTm7pY5g_p",
        "outputId": "17bdf4c7-c7d6-43bf-9c56-7e24c16f6651"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value', 'description'],\n",
              "    num_rows: 3000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But we can't pass the texts directly into a model. A deep learning model expects numbers as inputs, not English sentences! So we need to do two things:\n",
        "\n",
        "- *Tokenization*: Split each text up into words (or actually, as we'll see, into *tokens*)\n",
        "- *Numericalization*: Convert each word (or token) into a number.\n",
        "\n",
        "The details about how this is done actually depend on the particular model we use. So first we'll need to pick a model. There are thousands of models available, but a reasonable starting point for nearly any NLP problem is to use this (replace \"small\" with \"large\" for a slower but more accurate model, once you've finished exploring):"
      ],
      "metadata": {
        "id": "0sAAk1315g_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "这个字符串是 Hugging Face 模型库（Model Hub）里预训练模型的“地址”或“名字”。\n",
        "'''\n",
        "model_nm = 'microsoft/deberta-v3-small'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:27.34511Z",
          "iopub.execute_input": "2022-04-19T22:50:27.34548Z",
          "iopub.status.idle": "2022-04-19T22:50:27.350321Z",
          "shell.execute_reply.started": "2022-04-19T22:50:27.345436Z",
          "shell.execute_reply": "2022-04-19T22:50:27.348895Z"
        },
        "trusted": true,
        "id": "OfE8xJ9W5g_z"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`AutoTokenizer` will create a tokenizer appropriate for a given model:"
      ],
      "metadata": {
        "id": "XhrIH46g5g_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
        "tokz = AutoTokenizer.from_pretrained(model_nm)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:27.352982Z",
          "iopub.execute_input": "2022-04-19T22:50:27.354027Z",
          "iopub.status.idle": "2022-04-19T22:50:32.888486Z",
          "shell.execute_reply.started": "2022-04-19T22:50:27.353989Z",
          "shell.execute_reply": "2022-04-19T22:50:32.887654Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHoqTK__5g_0",
        "outputId": "ff961fd7-9a38-44d6-8bad-92608e6b9ed8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's an example of how the tokenizer splits a text into \"tokens\" (which are like words, but can be sub-word pieces, as you see below):"
      ],
      "metadata": {
        "id": "BxUnCW_a5g_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokz.tokenize(\"G'day folks, I'm Pino from fast.ai!\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:32.889685Z",
          "iopub.execute_input": "2022-04-19T22:50:32.889972Z",
          "iopub.status.idle": "2022-04-19T22:50:32.896362Z",
          "shell.execute_reply.started": "2022-04-19T22:50:32.889936Z",
          "shell.execute_reply": "2022-04-19T22:50:32.895562Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYk0HByf5g_0",
        "outputId": "48b5611e-9d05-4626-8eca-7a809c7a9283"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁G',\n",
              " \"'\",\n",
              " 'day',\n",
              " '▁folks',\n",
              " ',',\n",
              " '▁I',\n",
              " \"'\",\n",
              " 'm',\n",
              " '▁Pino',\n",
              " '▁from',\n",
              " '▁fast',\n",
              " '.',\n",
              " 'ai',\n",
              " '!']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uncommon words will be split into pieces. The start of a new word is represented by `▁`:"
      ],
      "metadata": {
        "id": "FEb2nas15g_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokz.tokenize(\"A platypus is an ornithorhynchus anatinus.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:32.903864Z",
          "iopub.execute_input": "2022-04-19T22:50:32.904487Z",
          "iopub.status.idle": "2022-04-19T22:50:32.91109Z",
          "shell.execute_reply.started": "2022-04-19T22:50:32.904456Z",
          "shell.execute_reply": "2022-04-19T22:50:32.910229Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blv_qo-Q5g_0",
        "outputId": "8986e2a2-c118-453b-d156-a4c1003eb979"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁A',\n",
              " '▁platypus',\n",
              " '▁is',\n",
              " '▁an',\n",
              " '▁or',\n",
              " 'ni',\n",
              " 'tho',\n",
              " 'rhynch',\n",
              " 'us',\n",
              " '▁an',\n",
              " 'at',\n",
              " 'inus',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a simple function which tokenizes our inputs:"
      ],
      "metadata": {
        "id": "f1inbKao5g_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tok_func(x):\n",
        "  return tokz(x[\"description\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:32.912176Z",
          "iopub.execute_input": "2022-04-19T22:50:32.912536Z",
          "iopub.status.idle": "2022-04-19T22:50:32.918514Z",
          "shell.execute_reply.started": "2022-04-19T22:50:32.9125Z",
          "shell.execute_reply": "2022-04-19T22:50:32.917626Z"
        },
        "trusted": true,
        "id": "cBW6CqxL5g_0"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tok_ds[:5])  # 查看前5条数据"
      ],
      "metadata": {
        "id": "hixF4SUkDnpI",
        "outputId": "60c028f0-df23-4655-f691-43afe590a61f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'longitude': [-122.05, -118.3, -117.81, -118.36, -119.67], 'latitude': [37.37, 34.26, 33.78, 33.82, 36.33], 'housing_median_age': [27.0, 43.0, 27.0, 28.0, 19.0], 'total_rooms': [3885.0, 1510.0, 3589.0, 67.0, 1241.0], 'total_bedrooms': [661.0, 310.0, 507.0, 15.0, 244.0], 'population': [1537.0, 809.0, 1484.0, 49.0, 850.0], 'households': [606.0, 277.0, 495.0, 11.0, 237.0], 'median_income': [6.6085, 3.599, 5.7934, 6.1359, 2.9375], 'median_house_value': [344700.0, 176500.0, 270500.0, 330000.0, 81700.0], 'description': ['Location: (-122.05, 37.37); Median house value: $344700.0', 'Location: (-118.3, 34.26); Median house value: $176500.0', 'Location: (-117.81, 33.78); Median house value: $270500.0', 'Location: (-118.36, 33.82); Median house value: $330000.0', 'Location: (-119.67, 36.33); Median house value: $81700.0'], 'input_ids': [[1, 7792, 294, 287, 271, 23267, 260, 3586, 261, 4249, 260, 5422, 285, 346, 52014, 669, 772, 294, 419, 38714, 7372, 260, 693, 2], [1, 7792, 294, 287, 271, 23562, 260, 508, 261, 3802, 260, 3725, 285, 346, 52014, 669, 772, 294, 419, 28606, 2429, 260, 693, 2], [1, 7792, 294, 287, 271, 22347, 260, 9767, 261, 3542, 260, 9448, 285, 346, 52014, 669, 772, 294, 419, 22058, 2429, 260, 693, 2], [1, 7792, 294, 287, 271, 23562, 260, 4612, 261, 3542, 260, 9734, 285, 346, 52014, 669, 772, 294, 419, 21055, 528, 260, 693, 2], [1, 7792, 294, 287, 271, 23277, 260, 8014, 261, 3372, 260, 4629, 285, 346, 52014, 669, 772, 294, 419, 804, 58358, 260, 693, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run this quickly in parallel on every row in our dataset, use `map`:"
      ],
      "metadata": {
        "id": "u0aoGmKw5g_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tok_ds = ds.map(tok_func, batched=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:32.919819Z",
          "iopub.execute_input": "2022-04-19T22:50:32.920279Z",
          "iopub.status.idle": "2022-04-19T22:50:40.024032Z",
          "shell.execute_reply.started": "2022-04-19T22:50:32.920244Z",
          "shell.execute_reply": "2022-04-19T22:50:40.023189Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "26f91a16ef004bd1ad489ebb2a52f2db",
            "cf41dea108b6442c96bdf244e4aa2280",
            "d1193ff9ba78444699afca3724bc1062",
            "1a57f0b9bdb440838045d7e903a6fdf1",
            "e142c03a502946d188c30aa34c33ec34",
            "cf0061a96e8347429b3f5a13fc95d945",
            "9f815e599d534604ab619c27fb57c26c",
            "843524e8755946b9826509e224fec1ed",
            "1e29eb77fc72441b847af01d6898b4c8",
            "22968bee4ca348ecab4801eccaef37c6",
            "c71bcf5e12314d519b974325aa0e99c5"
          ]
        },
        "id": "awWA9_pg5g_1",
        "outputId": "9e55fa61-3265-4da2-a600-67bebb0ab508"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26f91a16ef004bd1ad489ebb2a52f2db"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This adds a new item to our dataset called `input_ids`. For instance, here is the input and IDs for the first row of our data:"
      ],
      "metadata": {
        "id": "AeBV5RLl5g_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "row = tok_ds[0]\n",
        "row['longitude'], row['input_ids']\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:40.025285Z",
          "iopub.execute_input": "2022-04-19T22:50:40.025768Z",
          "iopub.status.idle": "2022-04-19T22:50:40.033207Z",
          "shell.execute_reply.started": "2022-04-19T22:50:40.025726Z",
          "shell.execute_reply": "2022-04-19T22:50:40.032522Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYpA6syz5g_1",
        "outputId": "3703258e-fefe-48b4-ad8c-30adf3715c51"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-122.05,\n",
              " [1,\n",
              "  7792,\n",
              "  294,\n",
              "  287,\n",
              "  271,\n",
              "  23267,\n",
              "  260,\n",
              "  3586,\n",
              "  261,\n",
              "  4249,\n",
              "  260,\n",
              "  5422,\n",
              "  285,\n",
              "  346,\n",
              "  52014,\n",
              "  669,\n",
              "  772,\n",
              "  294,\n",
              "  419,\n",
              "  38714,\n",
              "  7372,\n",
              "  260,\n",
              "  693,\n",
              "  2])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, what are those IDs and where do they come from? The secret is that there's a list called `vocab` in the tokenizer which contains a unique integer for every possible token string. We can look them up like this, for instance to find the token for the word \"of\":"
      ],
      "metadata": {
        "id": "6fIGZSy05g_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokz.vocab['▁of']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:40.034423Z",
          "iopub.execute_input": "2022-04-19T22:50:40.035157Z",
          "iopub.status.idle": "2022-04-19T22:50:40.043664Z",
          "shell.execute_reply.started": "2022-04-19T22:50:40.035118Z",
          "shell.execute_reply": "2022-04-19T22:50:40.04286Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYjJE-AI5g_1",
        "outputId": "0c36ebad-c65b-4755-efb6-b597286911c9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "265"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking above at our input IDs, we do indeed see that `265` appears as expected.\n",
        "\n",
        "Finally, we need to prepare our labels. Transformers always assumes that your labels has the column name `labels`, but in our dataset it's currently `score`. Therefore, we need to rename it:"
      ],
      "metadata": {
        "id": "yMqEUwTi5g_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tok_ds = tok_ds.rename_columns({'latitude':'labels'})\n",
        "print(tok_ds.column_names)\n",
        "print(tok_ds)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:40.044835Z",
          "iopub.execute_input": "2022-04-19T22:50:40.045192Z",
          "iopub.status.idle": "2022-04-19T22:50:40.05338Z",
          "shell.execute_reply.started": "2022-04-19T22:50:40.045156Z",
          "shell.execute_reply": "2022-04-19T22:50:40.05267Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOn2X-AB5g_1",
        "outputId": "4e7ebd6e-e983-46a5-870f-589384ce8b14"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['longitude', 'labels', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value', 'description', 'input_ids', 'token_type_ids', 'attention_mask']\n",
            "Dataset({\n",
            "    features: ['longitude', 'labels', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value', 'description', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "    num_rows: 3000\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've prepared our tokens and labels, we need to create our validation set."
      ],
      "metadata": {
        "id": "76GLVl5u5g_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test and validation sets"
      ],
      "metadata": {
        "id": "l5Wlflh85g_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may have noticed that our directory contained another file:"
      ],
      "metadata": {
        "id": "FpNUqf6q5g_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_df = pd.read_csv(path/'test.csv')\n",
        "eval_df.describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:40.054687Z",
          "iopub.execute_input": "2022-04-19T22:50:40.055436Z",
          "iopub.status.idle": "2022-04-19T22:50:40.080344Z",
          "shell.execute_reply.started": "2022-04-19T22:50:40.055398Z",
          "shell.execute_reply": "2022-04-19T22:50:40.0797Z"
        },
        "trusted": true,
        "id": "Xtn3Q_hh5g_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the *test set*. Possibly the most important idea in machine learning is that of having separate training, validation, and test data sets."
      ],
      "metadata": {
        "id": "z9Ck0FQW5g_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation set"
      ],
      "metadata": {
        "heading_collapsed": true,
        "id": "DnVVLj-y5g_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To explain the motivation, let's start simple, and imagine we're trying to fit a model where the true relationship is this quadratic:"
      ],
      "metadata": {
        "hidden": true,
        "id": "CjrG10hf5g_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x): return -3*x**2 + 2*x + 20"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:40.081507Z",
          "iopub.execute_input": "2022-04-19T22:50:40.083018Z",
          "iopub.status.idle": "2022-04-19T22:50:40.086665Z",
          "shell.execute_reply.started": "2022-04-19T22:50:40.082981Z",
          "shell.execute_reply": "2022-04-19T22:50:40.085797Z"
        },
        "trusted": true,
        "id": "m766cUSs5g_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately matplotlib (the most common library for plotting in Python) doesn't come with a way to visualize a function, so we'll write something to do this ourselves:"
      ],
      "metadata": {
        "hidden": true,
        "id": "LzySGRTq5g_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, matplotlib.pyplot as plt\n",
        "\n",
        "def plot_function(f, min=-2.1, max=2.1, color='r'):\n",
        "    x = np.linspace(min,max, 100)[:,None]\n",
        "    plt.plot(x, f(x), color)"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:40.087927Z",
          "iopub.execute_input": "2022-04-19T22:50:40.08842Z",
          "iopub.status.idle": "2022-04-19T22:50:40.09535Z",
          "shell.execute_reply.started": "2022-04-19T22:50:40.088386Z",
          "shell.execute_reply": "2022-04-19T22:50:40.094666Z"
        },
        "trusted": true,
        "id": "p8ApnOl85g_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's what our function looks like:"
      ],
      "metadata": {
        "hidden": true,
        "id": "4R7E_Bv35g_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_function(f)"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:40.096774Z",
          "iopub.execute_input": "2022-04-19T22:50:40.097207Z",
          "iopub.status.idle": "2022-04-19T22:50:40.302644Z",
          "shell.execute_reply.started": "2022-04-19T22:50:40.097166Z",
          "shell.execute_reply": "2022-04-19T22:50:40.301994Z"
        },
        "trusted": true,
        "id": "5zy61BiW5g_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For instance, perhaps we've measured the height above ground of an object before and after some event. The measurements will have some random error. We can use numpy's random number generator to simulate that. I like to use `seed` when writing about simulations like this so that I know you'll see the same thing I do:"
      ],
      "metadata": {
        "hidden": true,
        "id": "qtJbVP7x5g_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import normal,seed,uniform\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:40.303814Z",
          "iopub.execute_input": "2022-04-19T22:50:40.304201Z",
          "iopub.status.idle": "2022-04-19T22:50:40.308089Z",
          "shell.execute_reply.started": "2022-04-19T22:50:40.304166Z",
          "shell.execute_reply": "2022-04-19T22:50:40.307332Z"
        },
        "trusted": true,
        "id": "w-Wj5_035g_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a function `add_noise` that adds some random variation to an array:"
      ],
      "metadata": {
        "hidden": true,
        "id": "mCc_3gze5g_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def noise(x, scale): return normal(scale=scale, size=x.shape)\n",
        "def add_noise(x, mult, add): return x * (1+noise(x,mult)) + noise(x,add)"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:40.309302Z",
          "iopub.execute_input": "2022-04-19T22:50:40.310083Z",
          "iopub.status.idle": "2022-04-19T22:50:40.317335Z",
          "shell.execute_reply.started": "2022-04-19T22:50:40.310049Z",
          "shell.execute_reply": "2022-04-19T22:50:40.316644Z"
        },
        "trusted": true,
        "id": "qIKjGKl65g_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use it to simulate some measurements evenly distributed over time:"
      ],
      "metadata": {
        "hidden": true,
        "id": "IeqI9-S25g_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(-2, 2, num=20)[:,None]\n",
        "y = add_noise(f(x), 0.2, 1.3)\n",
        "plt.scatter(x,y);"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:40.318641Z",
          "iopub.execute_input": "2022-04-19T22:50:40.318943Z",
          "iopub.status.idle": "2022-04-19T22:50:40.538437Z",
          "shell.execute_reply.started": "2022-04-19T22:50:40.318907Z",
          "shell.execute_reply": "2022-04-19T22:50:40.537815Z"
        },
        "trusted": true,
        "id": "yHhdZ7uH5g_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's see what happens if we *underfit* or *overfit* these predictions. To do that, we'll create a function that fits a polynomial of some degree (e.g. a line is degree 1, quadratic is degree 2, cubic is degree 3, etc). The details of how this function works don't matter too much so feel free to skip over it if you like!  (PS: if you're not sure about the jargon around polynomials, here's a [great video](https://www.youtube.com/watch?v=ffLLmV4mZwU) which teaches you what you'll need to know.)"
      ],
      "metadata": {
        "hidden": true,
        "id": "WuKfAydJ5g_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "def plot_poly(degree):\n",
        "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
        "    model.fit(x, y)\n",
        "    plt.scatter(x,y)\n",
        "    plot_function(model.predict)"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:40.539573Z",
          "iopub.execute_input": "2022-04-19T22:50:40.539829Z",
          "iopub.status.idle": "2022-04-19T22:50:41.55072Z",
          "shell.execute_reply.started": "2022-04-19T22:50:40.539771Z",
          "shell.execute_reply": "2022-04-19T22:50:41.54997Z"
        },
        "trusted": true,
        "id": "1oV4kVKR5g_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, what happens if we fit a line (a \"degree 1 polynomial\") to our measurements?"
      ],
      "metadata": {
        "hidden": true,
        "id": "ywO6wHVa5g_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_poly(1)"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:41.552351Z",
          "iopub.execute_input": "2022-04-19T22:50:41.552615Z",
          "iopub.status.idle": "2022-04-19T22:50:41.805475Z",
          "shell.execute_reply.started": "2022-04-19T22:50:41.552578Z",
          "shell.execute_reply": "2022-04-19T22:50:41.80484Z"
        },
        "trusted": true,
        "id": "7P9_hrcV5g_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see, the points on the red line (the line we fitted) aren't very close at all. This is *under-fit* -- there's not enough detail in our function to match our data.\n",
        "\n",
        "And what happens if we fit a degree 10 polynomial to our measurements?"
      ],
      "metadata": {
        "hidden": true,
        "id": "3qyCEC3V5g_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_poly(10)"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:41.806743Z",
          "iopub.execute_input": "2022-04-19T22:50:41.806999Z",
          "iopub.status.idle": "2022-04-19T22:50:41.990392Z",
          "shell.execute_reply.started": "2022-04-19T22:50:41.806965Z",
          "shell.execute_reply": "2022-04-19T22:50:41.989678Z"
        },
        "trusted": true,
        "id": "IQRKgsgb5g_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well now it fits our data better, but it doesn't look like it'll do a great job predicting points other than those we measured -- especially those in earlier or later time periods. This is *over-fit* -- there's too much detail such that the model fits our points, but not the underlying process we really care about.\n",
        "\n",
        "Let's try a degree 2 polynomial (a quadratic), and compare it to our \"true\" function (in blue):"
      ],
      "metadata": {
        "hidden": true,
        "id": "S8q5nyye5g_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_poly(2)\n",
        "plot_function(f, color='b')"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:41.991733Z",
          "iopub.execute_input": "2022-04-19T22:50:41.992042Z",
          "iopub.status.idle": "2022-04-19T22:50:42.181247Z",
          "shell.execute_reply.started": "2022-04-19T22:50:41.991988Z",
          "shell.execute_reply": "2022-04-19T22:50:42.180598Z"
        },
        "trusted": true,
        "id": "M9xC8qOu5g_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's not bad at all!\n",
        "\n",
        "So, how do we recognise whether our models are under-fit, over-fit, or \"just right\"? We use a *validation set*. This is a set of data that we \"hold out\" from training -- we don't let our model see it at all. If you use the fastai library, it automatically creates a validation set for you if you don't have one, and will always report metrics (measurements of the accuracy of a model) using the validation set.\n",
        "\n",
        "The validation set is *only* ever used to see how we're doing. It's *never* used as inputs to training the model.\n",
        "\n",
        "Transformers uses a `DatasetDict` for holding your training and validation sets. To create one that contains 25% of our data for the validation set, and 75% for the training set, use `train_test_split`:"
      ],
      "metadata": {
        "hidden": true,
        "id": "F7k-QwlQ5g_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dds = tok_ds.train_test_split(0.25, seed=42)\n",
        "dds"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:42.182472Z",
          "iopub.execute_input": "2022-04-19T22:50:42.182706Z",
          "iopub.status.idle": "2022-04-19T22:50:42.206436Z",
          "shell.execute_reply.started": "2022-04-19T22:50:42.182674Z",
          "shell.execute_reply": "2022-04-19T22:50:42.205623Z"
        },
        "trusted": true,
        "id": "cWSnPSwQ5g_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see above, the validation set here is called `test` and not `validate`, so be careful!\n",
        "\n",
        "In practice, a random split like we've used here might not be a good idea -- here's what Dr Rachel Thomas has to say about it:\n",
        "\n",
        "> \"*One of the most likely culprits for this disconnect between results in development vs results in production is a poorly chosen validation set (or even worse, no validation set at all). Depending on the nature of your data, choosing a validation set can be the most important step. Although sklearn offers a `train_test_split` method, this method takes a random subset of the data, which is a poor choice for many real-world problems.*\"\n",
        "\n",
        "I strongly recommend reading her article [How (and why) to create a good validation set](https://www.fast.ai/2017/11/13/validation-sets/) to more fully understand this critical topic."
      ],
      "metadata": {
        "hidden": true,
        "id": "zq8us8y95g_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test set"
      ],
      "metadata": {
        "heading_collapsed": true,
        "id": "ij_AMHNg5g_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So that's the validation set explained, and created. What about the \"test set\" then -- what's that for?\n",
        "\n",
        "The *test set* is yet another dataset that's held out from training. But it's held out from reporting metrics too! The accuracy of your model on the test set is only ever checked after you've completed your entire training process, including trying different models, training methods, data processing, etc.\n",
        "\n",
        "You see, as you try all these different things, to see their impact on the metrics on the validation set, you might just accidentally find a few things that entirely coincidentally improve your validation set metrics, but aren't really better in practice. Given enough time and experiments, you'll find lots of these coincidental improvements. That means you're actually over-fitting to your validation set!\n",
        "\n",
        "That's why we keep a test set held back. Kaggle's public leaderboard is like a test set that you can check from time to time. But don't check too often, or you'll be even over-fitting to the test set!\n",
        "\n",
        "Kaggle has a *second* test set, which is yet another held-out dataset that's only used at the *end* of the competition to assess your predictions. That's called the \"private leaderboard\". Here's a [great post](https://gregpark.io/blog/Kaggle-Psychopathy-Postmortem/) about what can happen if you overfit to the public leaderboard.\n",
        "\n",
        "We'll use `eval` as our name for the test set, to avoid confusion with the `test` dataset that was created above."
      ],
      "metadata": {
        "hidden": true,
        "id": "552xXzP35g_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_df['input'] = 'TEXT1: ' + eval_df.context + '; TEXT2: ' + eval_df.target + '; ANC1: ' + eval_df.anchor\n",
        "eval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:42.208514Z",
          "iopub.execute_input": "2022-04-19T22:50:42.209142Z",
          "iopub.status.idle": "2022-04-19T22:50:43.285224Z",
          "shell.execute_reply.started": "2022-04-19T22:50:42.209113Z",
          "shell.execute_reply": "2022-04-19T22:50:43.284504Z"
        },
        "trusted": true,
        "id": "8KBpn00x5g_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics and correlation"
      ],
      "metadata": {
        "heading_collapsed": true,
        "id": "Knz-wfqp5g_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we're training a model, there will be one or more *metrics* that we're interested in maximising or minimising. These are the measurements that should, hopefully, represent how well our model will works for us.\n",
        "\n",
        "In real life, outside of Kaggle, things not easy... As my partner Dr Rachel Thomas notes in [The problem with metrics is a big problem for AI](https://www.fast.ai/2019/09/24/metrics/):\n",
        "\n",
        ">  At their heart, what most current AI approaches do is to optimize metrics. The practice of optimizing metrics is not new nor unique to AI, yet AI can be particularly efficient (even too efficient!) at doing so. This is important to understand, because any risks of optimizing metrics are heightened by AI. While metrics can be useful in their proper place, there are harms when they are unthinkingly applied. Some of the scariest instances of algorithms run amok all result from over-emphasizing metrics. We have to understand this dynamic in order to understand the urgent risks we are facing due to misuse of AI.\n",
        "\n",
        "In Kaggle, however, it's very straightforward to know what metric to use: Kaggle will tell you! According to this competition's [evaluation page](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/overview/evaluation), \"*submissions are evaluated on the [Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) between the predicted and actual similarity scores*.\" This coefficient is usually abbreviated using the single letter *r*. It is the most widely used measure of the degree of relationship between two variables.\n",
        "\n",
        "r can vary between `-1`, which means perfect inverse correlation, and `+1`, which means perfect positive correlation. The mathematical formula for it is much less important than getting a good intuition for what the different values look like. To start to get that intuition, let's look at some examples using the [California Housing](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset) dataset, which shows \"*is the median house value for California districts, expressed in hundreds of thousands of dollars*\". This dataset is provided by the excellent [scikit-learn](https://scikit-learn.org/stable/) library, which is the most widely used library for machine learning outside of deep learning."
      ],
      "metadata": {
        "hidden": true,
        "id": "fVq2IMqL5g_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "housing = fetch_california_housing(as_frame=True)\n",
        "housing = housing['data'].join(housing['target']).sample(1000, random_state=52)\n",
        "housing.head()"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:43.286609Z",
          "iopub.execute_input": "2022-04-19T22:50:43.287069Z",
          "iopub.status.idle": "2022-04-19T22:50:45.695379Z",
          "shell.execute_reply.started": "2022-04-19T22:50:43.287033Z",
          "shell.execute_reply": "2022-04-19T22:50:45.694638Z"
        },
        "trusted": true,
        "id": "N_vWtTtk5g_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see all the correlation coefficients for every combination of columns in this dataset by calling `np.corrcoef`:"
      ],
      "metadata": {
        "hidden": true,
        "id": "ls_8WXz15g_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(precision=2, suppress=True)\n",
        "\n",
        "np.corrcoef(housing, rowvar=False)"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:45.696556Z",
          "iopub.execute_input": "2022-04-19T22:50:45.696814Z",
          "iopub.status.idle": "2022-04-19T22:50:45.706279Z",
          "shell.execute_reply.started": "2022-04-19T22:50:45.696764Z",
          "shell.execute_reply": "2022-04-19T22:50:45.705491Z"
        },
        "trusted": true,
        "id": "Aa6uIXRX5g_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This works well when we're getting a bunch of values at once, but it's overkill when we want a single coefficient:"
      ],
      "metadata": {
        "hidden": true,
        "id": "_NlReTjx5g_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.corrcoef(housing.MedInc, housing.MedHouseVal)"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:45.707653Z",
          "iopub.execute_input": "2022-04-19T22:50:45.707925Z",
          "iopub.status.idle": "2022-04-19T22:50:45.714801Z",
          "shell.execute_reply.started": "2022-04-19T22:50:45.70789Z",
          "shell.execute_reply": "2022-04-19T22:50:45.714099Z"
        },
        "trusted": true,
        "id": "hCTpk0y05g_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, we'll create this little function to just return the single number we need given a pair of variables:"
      ],
      "metadata": {
        "hidden": true,
        "id": "cR7UlHnQ5g_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corr(x,y): return np.corrcoef(x,y)[0][1]\n",
        "\n",
        "corr(housing.MedInc, housing.MedHouseVal)"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:45.716399Z",
          "iopub.execute_input": "2022-04-19T22:50:45.716984Z",
          "iopub.status.idle": "2022-04-19T22:50:45.725866Z",
          "shell.execute_reply.started": "2022-04-19T22:50:45.716828Z",
          "shell.execute_reply": "2022-04-19T22:50:45.724914Z"
        },
        "trusted": true,
        "id": "u_r3rXub5g_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll look at a few examples of correlations, using this function (the details of the function don't matter too much):"
      ],
      "metadata": {
        "hidden": true,
        "id": "tOvYo6i75g_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_corr(df, a, b):\n",
        "    x,y = df[a],df[b]\n",
        "    plt.scatter(x,y, alpha=0.5, s=4)\n",
        "    plt.title(f'{a} vs {b}; r: {corr(x, y):.2f}')"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:45.727239Z",
          "iopub.execute_input": "2022-04-19T22:50:45.727521Z",
          "iopub.status.idle": "2022-04-19T22:50:45.73348Z",
          "shell.execute_reply.started": "2022-04-19T22:50:45.727485Z",
          "shell.execute_reply": "2022-04-19T22:50:45.732695Z"
        },
        "trusted": true,
        "id": "OiInZeok5g_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK, let's check out the correlation between income and house value:"
      ],
      "metadata": {
        "hidden": true,
        "id": "vQxdxWOq5g_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_corr(housing, 'MedInc', 'MedHouseVal')"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:45.734925Z",
          "iopub.execute_input": "2022-04-19T22:50:45.735373Z",
          "iopub.status.idle": "2022-04-19T22:50:45.934349Z",
          "shell.execute_reply.started": "2022-04-19T22:50:45.735339Z",
          "shell.execute_reply": "2022-04-19T22:50:45.933604Z"
        },
        "trusted": true,
        "id": "VrV9sx2w5g_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So that's what a correlation of 0.68 looks like. It's quite a close relationship, but there's still a lot of variation. (Incidentally, this also shows why looking at your data is so important -- we can see clearly in this plot that house prices above $500,000 seem to have been truncated to that maximum value).\n",
        "\n",
        "Let's take a look at another pair:"
      ],
      "metadata": {
        "hidden": true,
        "id": "BdR5y7Fr5g_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_corr(housing, 'MedInc', 'AveRooms')"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:45.936529Z",
          "iopub.execute_input": "2022-04-19T22:50:45.936766Z",
          "iopub.status.idle": "2022-04-19T22:50:46.140068Z",
          "shell.execute_reply.started": "2022-04-19T22:50:45.936734Z",
          "shell.execute_reply": "2022-04-19T22:50:46.139406Z"
        },
        "trusted": true,
        "id": "Uwc8byaA5g_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The relationship looks like it is similarly close to the previous example, but r is much lower than the income vs valuation case. Why is that? The reason is that there are a lot of *outliers* -- values of `AveRooms` well outside the mean.\n",
        "\n",
        "r is very sensitive to outliers. If there's outliers in your data, then the relationship between them will dominate the metric. In this case, the houses with a very high number of rooms don't tend to be that valuable, so it's decreasing r from where it would otherwise be.\n",
        "\n",
        "Let's remove the outliers and try again:"
      ],
      "metadata": {
        "hidden": true,
        "id": "ipwPJv-z5g_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subset = housing[housing.AveRooms<15]\n",
        "show_corr(subset, 'MedInc', 'AveRooms')"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:46.141412Z",
          "iopub.execute_input": "2022-04-19T22:50:46.141685Z",
          "iopub.status.idle": "2022-04-19T22:50:46.338356Z",
          "shell.execute_reply.started": "2022-04-19T22:50:46.141649Z",
          "shell.execute_reply": "2022-04-19T22:50:46.337634Z"
        },
        "trusted": true,
        "id": "TPVHe9b05g_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we expected, now the correlation is very similar to our first comparison.\n",
        "\n",
        "Here's another relationship using `AveRooms` on the subset:"
      ],
      "metadata": {
        "hidden": true,
        "id": "lPJ4Pcyr5g_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_corr(subset, 'MedHouseVal', 'AveRooms')"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:46.339686Z",
          "iopub.execute_input": "2022-04-19T22:50:46.339954Z",
          "iopub.status.idle": "2022-04-19T22:50:46.525259Z",
          "shell.execute_reply.started": "2022-04-19T22:50:46.33992Z",
          "shell.execute_reply": "2022-04-19T22:50:46.5246Z"
        },
        "trusted": true,
        "id": "X8XQhf4F5g_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this level, with r of 0.34, the relationship is becoming quite weak.\n",
        "\n",
        "Let's look at one more:"
      ],
      "metadata": {
        "hidden": true,
        "id": "NfzAB-O-5g_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_corr(subset, 'HouseAge', 'AveRooms')"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:46.526533Z",
          "iopub.execute_input": "2022-04-19T22:50:46.526758Z",
          "iopub.status.idle": "2022-04-19T22:50:46.713907Z",
          "shell.execute_reply.started": "2022-04-19T22:50:46.526726Z",
          "shell.execute_reply": "2022-04-19T22:50:46.71321Z"
        },
        "trusted": true,
        "id": "Pp3zr3tC5g_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see here, a correlation of -0.2 shows a very weak negative trend.\n",
        "\n",
        "We've seen now examples of a variety of levels of correlation coefficient, so hopefully you're getting a good sense of what this metric means.\n",
        "\n",
        "Transformers expects metrics to be returned as a `dict`, since that way the trainer knows what label to use, so let's create a function to do that:"
      ],
      "metadata": {
        "hidden": true,
        "id": "ZJKyacgG5g_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corr_d(eval_pred): return {'pearson': corr(*eval_pred)}"
      ],
      "metadata": {
        "hidden": true,
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:46.714967Z",
          "iopub.execute_input": "2022-04-19T22:50:46.715747Z",
          "iopub.status.idle": "2022-04-19T22:50:46.720156Z",
          "shell.execute_reply.started": "2022-04-19T22:50:46.715707Z",
          "shell.execute_reply": "2022-04-19T22:50:46.719423Z"
        },
        "trusted": true,
        "id": "RgRSl1tO5g_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "RtmulJvr5g_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training our model"
      ],
      "metadata": {
        "id": "GgIEDJ5C5g_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train a model in Transformers we'll need this:"
      ],
      "metadata": {
        "id": "KbeVqbQQ5g_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments,Trainer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:46.721475Z",
          "iopub.execute_input": "2022-04-19T22:50:46.722217Z",
          "iopub.status.idle": "2022-04-19T22:50:50.49162Z",
          "shell.execute_reply.started": "2022-04-19T22:50:46.722181Z",
          "shell.execute_reply": "2022-04-19T22:50:50.490895Z"
        },
        "trusted": true,
        "id": "LgyzD0wc5g_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We pick a batch size that fits our GPU, and small number of epochs so we can run experiments quickly:"
      ],
      "metadata": {
        "id": "rOWVO5V95g_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 128\n",
        "epochs = 4"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:50.493123Z",
          "iopub.execute_input": "2022-04-19T22:50:50.493385Z",
          "iopub.status.idle": "2022-04-19T22:50:50.497666Z",
          "shell.execute_reply.started": "2022-04-19T22:50:50.493351Z",
          "shell.execute_reply": "2022-04-19T22:50:50.496574Z"
        },
        "trusted": true,
        "id": "xYyvjgGl5g_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most important hyperparameter is the learning rate. fastai provides a learning rate finder to help you figure this out, but Transformers doesn't, so you'll just have to use trial and error. The idea is to find the largest value you can, but which doesn't result in training failing."
      ],
      "metadata": {
        "id": "KQsQg_7y5g_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 8e-5"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:50.499023Z",
          "iopub.execute_input": "2022-04-19T22:50:50.499529Z",
          "iopub.status.idle": "2022-04-19T22:50:50.50552Z",
          "shell.execute_reply.started": "2022-04-19T22:50:50.499493Z",
          "shell.execute_reply": "2022-04-19T22:50:50.504727Z"
        },
        "trusted": true,
        "id": "4aixi0yE5g_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformers uses the `TrainingArguments` class to set up arguments. Don't worry too much about the values we're using here -- they should generally work fine in most cases. It's just the 3 parameters above that you may need to change for different models."
      ],
      "metadata": {
        "id": "KhDDfoeV5g_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n",
        "    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n",
        "    num_train_epochs=epochs, weight_decay=0.01, report_to='none')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:50.511094Z",
          "iopub.execute_input": "2022-04-19T22:50:50.511688Z",
          "iopub.status.idle": "2022-04-19T22:50:50.571158Z",
          "shell.execute_reply.started": "2022-04-19T22:50:50.511653Z",
          "shell.execute_reply": "2022-04-19T22:50:50.570503Z"
        },
        "trusted": true,
        "id": "o2rwpePY5g_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now create our model, and `Trainer`, which is a class which combines the data and model together (just like `Learner` in fastai):"
      ],
      "metadata": {
        "id": "lusFfNn-5g_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n",
        "trainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n",
        "                  tokenizer=tokz, compute_metrics=corr_d)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:50:50.572318Z",
          "iopub.execute_input": "2022-04-19T22:50:50.57282Z",
          "iopub.status.idle": "2022-04-19T22:51:06.368797Z",
          "shell.execute_reply.started": "2022-04-19T22:50:50.57276Z",
          "shell.execute_reply": "2022-04-19T22:51:06.368066Z"
        },
        "trusted": true,
        "id": "SG2QvAAo5g_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see, Transformers spits out lots of warnings. You can safely ignore them.\n",
        "\n",
        "Let's train our model!"
      ],
      "metadata": {
        "id": "fyHAzaer5g_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train();"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:51:06.370099Z",
          "iopub.execute_input": "2022-04-19T22:51:06.370349Z",
          "iopub.status.idle": "2022-04-19T22:56:03.884434Z",
          "shell.execute_reply.started": "2022-04-19T22:51:06.370314Z",
          "shell.execute_reply": "2022-04-19T22:56:03.883722Z"
        },
        "trusted": true,
        "id": "ZAXBiWN55g_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lots more warning from Transformers again -- you can ignore these as before.\n",
        "\n",
        "The key thing to look at is the \"Pearson\" value in table above. As you see, it's increasing, and is already above 0.8. That's great news! We can now submit our predictions to Kaggle if we want them to be scored on the official leaderboard. Let's get some predictions on the test set:"
      ],
      "metadata": {
        "id": "QvQWOQY25g_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = trainer.predict(eval_ds).predictions.astype(float)\n",
        "preds"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:56:03.885816Z",
          "iopub.execute_input": "2022-04-19T22:56:03.886213Z",
          "iopub.status.idle": "2022-04-19T22:56:03.939419Z",
          "shell.execute_reply.started": "2022-04-19T22:56:03.886175Z",
          "shell.execute_reply": "2022-04-19T22:56:03.938611Z"
        },
        "trusted": true,
        "id": "tTouFdut5g_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look out - some of our predictions are <0, or >1! This once again shows the value of remember to actually *look* at your data. Let's fix those out-of-bounds predictions:"
      ],
      "metadata": {
        "id": "qCpuHUDq5g_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.clip(preds, 0, 1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:56:03.940755Z",
          "iopub.execute_input": "2022-04-19T22:56:03.941019Z",
          "iopub.status.idle": "2022-04-19T22:56:03.94481Z",
          "shell.execute_reply.started": "2022-04-19T22:56:03.940986Z",
          "shell.execute_reply": "2022-04-19T22:56:03.944055Z"
        },
        "trusted": true,
        "id": "BGkVfs4Q5g_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:56:03.94601Z",
          "iopub.execute_input": "2022-04-19T22:56:03.946624Z",
          "iopub.status.idle": "2022-04-19T22:56:03.957676Z",
          "shell.execute_reply.started": "2022-04-19T22:56:03.946586Z",
          "shell.execute_reply": "2022-04-19T22:56:03.956977Z"
        },
        "trusted": true,
        "id": "30IOZ4AE5g_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK, now we're ready to create our submission file. If you save a CSV in your notebook, you will get the option to submit it later."
      ],
      "metadata": {
        "id": "pXu5wRVS5g_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "\n",
        "submission = datasets.Dataset.from_dict({\n",
        "    'id': eval_ds['id'],\n",
        "    'score': preds\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-19T22:56:03.959091Z",
          "iopub.execute_input": "2022-04-19T22:56:03.959387Z",
          "iopub.status.idle": "2022-04-19T22:56:04.014925Z",
          "shell.execute_reply.started": "2022-04-19T22:56:03.959351Z",
          "shell.execute_reply": "2022-04-19T22:56:04.014252Z"
        },
        "trusted": true,
        "id": "6MJJBJx55g_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately this is a *code competition* and internet access is disabled. That means the `pip install datasets` command we used above won't work if you want to submit to Kaggle. To fix this, you'll need to download the pip installers to Kaggle first, as [described here](https://www.kaggle.com/c/severstal-steel-defect-detection/discussion/113195). Once you've done that, disable internet in your notebook, go to the Kaggle leaderboards page, and click the *Submission* button."
      ],
      "metadata": {
        "id": "X7TebYbp5g_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The end"
      ],
      "metadata": {
        "id": "CIvdWAkG5g_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you're ready to go deeper, take a look at my [Iterate Like a Grandmaster](https://www.kaggle.com/code/jhoward/iterate-like-a-grandmaster/) notebook.\n",
        "\n",
        "Thanks for reading! This has been a bit of an experiment for me -- I've never done an \"absolute beginners\" guide before on Kaggle. I hope you like it! If you do, I'd greatly appreciate an upvote. Don't hesitate to add a comment if you have any questions or thoughts to add."
      ],
      "metadata": {
        "id": "bzFrs0jb5g__"
      }
    }
  ]
}